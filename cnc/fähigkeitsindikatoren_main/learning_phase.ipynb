{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import load_data\n",
    "import Zuschneiden\n",
    "import Features\n",
    "import get_classes\n",
    "import cluster_representatives\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial data and calculate sequences\n",
    "matrix,static_features,kopfzeile=load_data.load_matrix(r\"..\\CSV_SDMflex\\SDMflex_V2_Training_final.csv\")   # load learning Data\n",
    "Schnitt = Zuschneiden.Sectioning(matrix,kopfzeile,G=1, c=True)   # calculate sequences\n",
    "Zuschnitte = Features.region_feature(matrix,Schnitt,kopfzeile,static_features)   # calculate features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.997298\n",
      "5.266\n"
     ]
    }
   ],
   "source": [
    "# get feature vector for segmentation\n",
    "features=[]\n",
    "for i in range(len(Zuschnitte)):\n",
    "    # Used features are distance (x,y,z), average spindle speed and duration (spindlespeed is diveded by 6 due to recording)\n",
    "    features += [(Zuschnitte[i][1][0], Zuschnitte[i][1][1],Zuschnitte[i][1][2], Zuschnitte[i][1][4]/6, Zuschnitte[i][1][5])]\n",
    "features = np.array(features)\n",
    "\n",
    "# Initial Segmentation\n",
    "lables = get_classes.init_class(features)\n",
    "#Zuschnitte[i][3][0][0],\n",
    "\n",
    "print((Zuschnitte))\n",
    "\n",
    "print((Zuschnitte[1][1][0]))\n",
    "print((Zuschnitte[1][3][0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.997298, 50.0, 0.056114108695588215, 4974.999983179725, 8.776652173913044], [10.0, 50.0, 0.049511853658528004, 4974.999983859225, 7.720650406504067]]\n",
      "[[0.0, 0.0, 0.0033927684939303268, 4.944096503002517e-06, 0.0009375590718628427], [0.0, 0.0, 0.0018439728481640905, 4.767174758795743e-06, 0.000936901482334862]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and save the representative cluster features for inline classification\n",
    "class_features, class_std = cluster_representatives.rep_features(lables, features)\n",
    "\n",
    "with open('data/class_features.pkl', 'wb') as f:\n",
    "    pickle.dump(class_features, f)\n",
    "\n",
    "with open('data/class_std.pkl', 'wb') as f:\n",
    "    pickle.dump(class_std, f)\n",
    "\n",
    "\n",
    "print(class_features)\n",
    "print(class_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill model matrix with models\n",
    "class_rep, class_len_rep = cluster_representatives.get_cluster_ts(Zuschnitte, lables)   # get the sorted representative cluster timeseries (cluster --> source --> all ts)\n",
    "\n",
    "index = np.linspace(kopfzeile.index('Speed_SP')+1, len(kopfzeile)-1, len(kopfzeile) - kopfzeile.index('Speed_SP')-1).astype(int)   # get relevant indices\n",
    "\n",
    "# Get the relevant lables (-1 --> noise)\n",
    "class_nrs = np.unique(lables).tolist()\n",
    "\n",
    "if class_nrs.__contains__(-1):\n",
    "    class_nrs.remove(-1)\n",
    "\n",
    "class_index_models = []   # Matrix for the representative models\n",
    "index_matrix = []   #   frame-matrix for indices\n",
    "\n",
    "for class_nr in class_nrs:\n",
    "    # check each cluster\n",
    "    class_index = []\n",
    "    class_index_vector = []\n",
    "\n",
    "    for i in index:\n",
    "        # get the signal-index model for each information signal\n",
    "        class_index += [cluster_representatives.signal_index(class_rep[class_nr][i], class_len_rep[class_nr])] \n",
    "        class_index_vector += [[]]\n",
    "\n",
    "    class_index_models += [class_index]\n",
    "    index_matrix += [class_index_vector]\n",
    "\n",
    "\n",
    "with open('data/index_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(index_matrix, f)\n",
    "\n",
    "with open('data/class_index_models.pkl', 'wb') as f:\n",
    "    pickle.dump(class_index_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_features0  class_features1  class_std0  class_std1\n",
      "0        13.997298        10.000000    0.000000    0.000000\n",
      "1        50.000000        50.000000    0.000000    0.000000\n",
      "2         0.056114         0.049512    0.003393    0.001844\n",
      "3      4974.999983      4974.999984    0.000005    0.000005\n",
      "4         8.776652         7.720650    0.000938    0.000937\n"
     ]
    }
   ],
   "source": [
    "ret_dict = {\n",
    "    'class_features0' : class_features[0],\n",
    "    'class_features1' : class_features[1],\n",
    "    'class_std0' : class_std[0],\n",
    "    'class_std1' : class_std[1]\n",
    "}\n",
    "data = pd.DataFrame.from_dict(ret_dict)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5db824c9802862709752f8b14eacc447d9d1e12fc0650393d2d96a1ec95ed5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
